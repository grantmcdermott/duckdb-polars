
# Clone of Original Repository!

This repo is a clone of [https://github.com/grantmcdermott/duckdb-polars](https://github.com/grantmcdermott/duckdb-polars).


# (Pretty) big data wrangling with DuckDB and Polars


- These materials were prepared as part of the
[Workshops for Ukraine](https://sites.google.com/view/dariia-mykhailyshyna/main/r-workshops-for-ukraine#h.xc2x33lbfxln)
series.
- The attendance fee is 20 EUR/USD. All proceeds from the workshop are going
towards aid orgnizations in Ukraine. If you are unable to attend, but would
still like to contribute, please consider sponsoring a student or colleague.
See the
[WFU website](https://sites.google.com/view/dariia-mykhailyshyna/main/r-workshops-for-ukraine#h.xc2x33lbfxln)
for details.

**Website:** https://grantmcdermott.com/duckdb-polars

**Date:** Thursday, May 2nd, 18:00 - 20:00 CEST (Rome, Berlin, Paris timezone).
A recording of the workshop will be available for attendees who cannot make
the live stream.

**Description:** This workshop will introduce you to [DuckDB](https://duckdb.org/) and
[Polars](https://github.com/pola-rs/polars), two data wrangling libraries at the
frontier of high-performance computation. (See
[benchmarks](https://duckdblabs.github.io/db-benchmark/).) In addition to being
extremely fast and portable, both DuckDB and Polars provide user-friendly
implementations across multiple languages. This makes them very well suited to
production and applied research settings, without the overhead of tools like
Spark. We will provide a variety of real-life examples in both R and Python,
with the aim of getting participants up and running as quickly as possible. We
will learn how wrangle datasets extending over several hundred million
observations in a matter of seconds or less, using only our laptops. And we will
learn how to scale to even larger contexts where the data exceeds our computersâ€™
RAM capacity. Finally, we will also discuss some complementary tools and how
these can be integrated for an efficient end-to-end workflow (data I/O ->
wrangling -> analysis).

_Disclaimer: The content for this workshop has been prepared, and is presented,
in my personal capacity. Any opinions expressed herein are my own and are not
necessarily shared by my employer. Please do not share any recorded material
without the express permission of myself or the workshop organisers._



### Meta info

* to get quarto to run with conda env, look at [this](https://thedatasavvycorner.com/blogs/08-quarto-conda-env)